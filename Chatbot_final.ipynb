{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_final.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nithinps021/Project_IISU/blob/main/Chatbot_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "R9e-EZdKri7e"
      },
      "outputs": [],
      "source": [
        "from urllib import response\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Bidirectional, Dropout, Dense, Activation, Flatten, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential,Model,load_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "data_file = open('intents_cleaned_1.json').read()\n",
        "intents = json.loads(data_file)\n",
        "intents=intents['intents']\n",
        "random.shuffle(intents)\n",
        "classes=[]\n",
        "alldata=[]\n",
        "responses={}\n",
        "for i in intents:\n",
        "\tif i['tag'] not in classes:\n",
        "\t\tclasses.append(i['tag'])\n",
        "\t\tresponses[i['tag']]=i['responses'][0]\n",
        "\tfor j in i['patterns']:\n",
        "\t\talldata.append([j,i['tag']])\n",
        "\n",
        "\n",
        "random.shuffle(alldata)\n",
        "tot_data=len(alldata)\n",
        "tot_classes=len(classes)\n",
        "x_train=np.array([])\n",
        "y_train=np.zeros(shape=(tot_data,tot_classes), dtype=np.uint8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp =spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def normalize(text):\n",
        "  text=nlp(text)\n",
        "  norm_text=[]\n",
        "  for token in text:\n",
        "    if not token.is_punct and not token.is_stop and not token.is_space:\n",
        "      norm_text.append(token.lemma_.lower())\n",
        "  return ' '.join(norm_text)\n",
        "\n",
        "for i in range(tot_data):\n",
        "  sen = normalize(alldata[i][0])\n",
        "  print(sen)\n",
        "  x_train=np.append(x_train,sen)\n",
        "  y_train[i][classes.index(alldata[i][1])]=1\n"
      ],
      "metadata": {
        "id": "QwkTmhhWm96M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=x_train\n",
        "Tokenizer = Tokenizer()\n",
        "Tokenizer.fit_on_texts(text) \n",
        "Tokenizer_vocab_size = len(Tokenizer.word_index) + 1\n",
        "Tokenizer_vocab_size, x_train.shape, y_train.shape\n",
        "\n",
        "\n",
        "print(x_train)\n",
        "\n",
        "x_val=x_train[0:157]\n",
        "y_val=y_train[0:157]\n",
        "\n",
        "x_train=x_train[157:]\n",
        "y_train=y_train[157:]\n",
        "\n",
        "X_train_encoded_words = Tokenizer.texts_to_sequences(x_train)\n",
        "X_val_encoded_words = Tokenizer.texts_to_sequences(x_val)\n",
        "X_train_encoded_padded_words = sequence.pad_sequences(X_train_encoded_words, maxlen =100)\n",
        "X_val_encoded_padded_words = sequence.pad_sequences(X_val_encoded_words, maxlen = 100)"
      ],
      "metadata": {
        "id": "yaIpfeOlntGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(Tokenizer_vocab_size,100, input_length = 100)) # Accepts the vector inputs\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(800, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(tot_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "Nadam = tf.keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Nadam, metrics=['accuracy'])\n",
        "history  = model.fit(X_train_encoded_padded_words,y_train, epochs = 100, batch_size=100, verbose=1, validation_data=(X_val_encoded_padded_words, y_val))\n",
        "model.save('gru3.h5')\n",
        "\n",
        "print(len(x_train),y_train)\n",
        "print(Tokenizer_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6bL3FnAnh2N",
        "outputId": "1ac20b58-7eee-4c7d-bb48-8c1ec5a6fbb8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 100, 100)          93100     \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 128)              63744     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 800)               103200    \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 800)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 200)               160200    \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 340)               68340     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 488,584\n",
            "Trainable params: 488,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/nadam.py:73: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Nadam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 9s 281ms/step - loss: 5.8300 - accuracy: 0.0072 - val_loss: 5.8320 - val_accuracy: 0.0255\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 5.8133 - accuracy: 0.0118 - val_loss: 5.8461 - val_accuracy: 0.0255\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 5.7544 - accuracy: 0.0137 - val_loss: 5.7683 - val_accuracy: 0.0255\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 5.5575 - accuracy: 0.0183 - val_loss: 5.6165 - val_accuracy: 0.0064\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 5.2358 - accuracy: 0.0281 - val_loss: 5.2688 - val_accuracy: 0.0510\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 4.7533 - accuracy: 0.0490 - val_loss: 4.9237 - val_accuracy: 0.0446\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 4.4150 - accuracy: 0.0791 - val_loss: 4.7015 - val_accuracy: 0.0764\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 4.0961 - accuracy: 0.1052 - val_loss: 4.2636 - val_accuracy: 0.1401\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 3.7696 - accuracy: 0.1425 - val_loss: 3.9931 - val_accuracy: 0.1975\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 3.4614 - accuracy: 0.1667 - val_loss: 3.7891 - val_accuracy: 0.2166\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 3.2212 - accuracy: 0.1974 - val_loss: 3.3897 - val_accuracy: 0.3248\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 3.0542 - accuracy: 0.2242 - val_loss: 3.2105 - val_accuracy: 0.3631\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 2.8380 - accuracy: 0.2556 - val_loss: 3.1057 - val_accuracy: 0.3567\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 5s 288ms/step - loss: 2.6750 - accuracy: 0.2869 - val_loss: 2.9511 - val_accuracy: 0.4076\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 2.5368 - accuracy: 0.3026 - val_loss: 2.8608 - val_accuracy: 0.4459\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 2.4043 - accuracy: 0.3471 - val_loss: 2.7353 - val_accuracy: 0.4777\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 3s 213ms/step - loss: 2.2772 - accuracy: 0.3673 - val_loss: 2.7605 - val_accuracy: 0.5096\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 2.2019 - accuracy: 0.3837 - val_loss: 2.5604 - val_accuracy: 0.5605\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 2.0657 - accuracy: 0.3993 - val_loss: 2.4976 - val_accuracy: 0.5605\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.9753 - accuracy: 0.4229 - val_loss: 2.3946 - val_accuracy: 0.5669\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.8668 - accuracy: 0.4588 - val_loss: 2.4946 - val_accuracy: 0.6051\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 4s 218ms/step - loss: 1.7690 - accuracy: 0.4830 - val_loss: 2.5962 - val_accuracy: 0.5796\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.6851 - accuracy: 0.4928 - val_loss: 2.3079 - val_accuracy: 0.5924\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.6206 - accuracy: 0.5190 - val_loss: 2.2823 - val_accuracy: 0.5987\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.5578 - accuracy: 0.5275 - val_loss: 2.3340 - val_accuracy: 0.6306\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.5918 - accuracy: 0.5248 - val_loss: 2.4229 - val_accuracy: 0.6306\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4916 - accuracy: 0.5477 - val_loss: 2.2720 - val_accuracy: 0.6624\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.4057 - accuracy: 0.5752 - val_loss: 2.4386 - val_accuracy: 0.6624\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2902 - accuracy: 0.6085 - val_loss: 2.2904 - val_accuracy: 0.6369\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.3601 - accuracy: 0.5915 - val_loss: 2.2972 - val_accuracy: 0.5924\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.3122 - accuracy: 0.6039 - val_loss: 2.2744 - val_accuracy: 0.6369\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2332 - accuracy: 0.6301 - val_loss: 2.3441 - val_accuracy: 0.6624\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2803 - accuracy: 0.6098 - val_loss: 2.1425 - val_accuracy: 0.6752\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.2281 - accuracy: 0.6405 - val_loss: 2.4394 - val_accuracy: 0.6497\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.2100 - accuracy: 0.6346 - val_loss: 2.3955 - val_accuracy: 0.6433\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 1.1198 - accuracy: 0.6497 - val_loss: 2.4995 - val_accuracy: 0.6624\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.0553 - accuracy: 0.6745 - val_loss: 2.3219 - val_accuracy: 0.6752\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 1.0777 - accuracy: 0.6556 - val_loss: 2.4856 - val_accuracy: 0.6688\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 1.0591 - accuracy: 0.6608 - val_loss: 2.2822 - val_accuracy: 0.6688\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 1.0721 - accuracy: 0.6621 - val_loss: 2.3748 - val_accuracy: 0.6688\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 1.0006 - accuracy: 0.6843 - val_loss: 2.2556 - val_accuracy: 0.7006\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.9890 - accuracy: 0.6935 - val_loss: 2.3815 - val_accuracy: 0.6815\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 1.0399 - accuracy: 0.6941 - val_loss: 2.3564 - val_accuracy: 0.6624\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.9979 - accuracy: 0.6856 - val_loss: 2.3256 - val_accuracy: 0.6752\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 1.0042 - accuracy: 0.6908 - val_loss: 2.3796 - val_accuracy: 0.6561\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.9469 - accuracy: 0.7000 - val_loss: 2.4119 - val_accuracy: 0.6561\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.9241 - accuracy: 0.7124 - val_loss: 2.2856 - val_accuracy: 0.7070\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.9975 - accuracy: 0.6948 - val_loss: 2.2537 - val_accuracy: 0.6943\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.9072 - accuracy: 0.7052 - val_loss: 2.1803 - val_accuracy: 0.7134\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.8207 - accuracy: 0.7418 - val_loss: 2.2380 - val_accuracy: 0.6943\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.8547 - accuracy: 0.7288 - val_loss: 2.3450 - val_accuracy: 0.6943\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 3s 214ms/step - loss: 0.9290 - accuracy: 0.7176 - val_loss: 2.3935 - val_accuracy: 0.7134\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.8998 - accuracy: 0.7157 - val_loss: 2.1454 - val_accuracy: 0.6943\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.8583 - accuracy: 0.7248 - val_loss: 2.3056 - val_accuracy: 0.6943\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.8629 - accuracy: 0.7268 - val_loss: 2.2728 - val_accuracy: 0.6752\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.8177 - accuracy: 0.7242 - val_loss: 2.2602 - val_accuracy: 0.7070\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.8376 - accuracy: 0.7314 - val_loss: 2.1906 - val_accuracy: 0.7261\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7630 - accuracy: 0.7686 - val_loss: 2.3563 - val_accuracy: 0.6943\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.7988 - accuracy: 0.7399 - val_loss: 2.4158 - val_accuracy: 0.6688\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7735 - accuracy: 0.7549 - val_loss: 2.3600 - val_accuracy: 0.6879\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.7515 - accuracy: 0.7641 - val_loss: 2.2871 - val_accuracy: 0.6943\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.7783 - accuracy: 0.7516 - val_loss: 2.4618 - val_accuracy: 0.6879\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.7020 - accuracy: 0.7850 - val_loss: 2.3474 - val_accuracy: 0.7197\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.7358 - accuracy: 0.7680 - val_loss: 2.4223 - val_accuracy: 0.7134\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.7635 - accuracy: 0.7595 - val_loss: 2.4507 - val_accuracy: 0.7006\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.7084 - accuracy: 0.7732 - val_loss: 2.4227 - val_accuracy: 0.7070\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.7073 - accuracy: 0.7647 - val_loss: 2.4651 - val_accuracy: 0.6879\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7423 - accuracy: 0.7595 - val_loss: 2.5261 - val_accuracy: 0.7134\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7334 - accuracy: 0.7647 - val_loss: 2.4378 - val_accuracy: 0.6815\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7343 - accuracy: 0.7667 - val_loss: 2.4347 - val_accuracy: 0.7006\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.6890 - accuracy: 0.7791 - val_loss: 2.5567 - val_accuracy: 0.7197\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 5s 291ms/step - loss: 0.7307 - accuracy: 0.7601 - val_loss: 2.4705 - val_accuracy: 0.6815\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.7083 - accuracy: 0.7706 - val_loss: 2.3944 - val_accuracy: 0.6815\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.6857 - accuracy: 0.7778 - val_loss: 2.5717 - val_accuracy: 0.7325\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 4s 221ms/step - loss: 0.6879 - accuracy: 0.7778 - val_loss: 2.4245 - val_accuracy: 0.7389\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.7284 - accuracy: 0.7641 - val_loss: 2.3574 - val_accuracy: 0.7134\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.6473 - accuracy: 0.7948 - val_loss: 2.5211 - val_accuracy: 0.7197\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.6853 - accuracy: 0.7876 - val_loss: 2.5064 - val_accuracy: 0.7006\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 3s 219ms/step - loss: 0.6880 - accuracy: 0.7824 - val_loss: 2.5281 - val_accuracy: 0.6879\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.6796 - accuracy: 0.7797 - val_loss: 2.4105 - val_accuracy: 0.7197\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.6869 - accuracy: 0.7804 - val_loss: 2.4598 - val_accuracy: 0.7070\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6556 - accuracy: 0.7837 - val_loss: 2.5437 - val_accuracy: 0.7261\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.6837 - accuracy: 0.7797 - val_loss: 2.7543 - val_accuracy: 0.7261\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.5897 - accuracy: 0.8065 - val_loss: 2.5806 - val_accuracy: 0.7325\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6542 - accuracy: 0.7817 - val_loss: 2.7633 - val_accuracy: 0.7325\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6453 - accuracy: 0.7843 - val_loss: 2.7279 - val_accuracy: 0.7134\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.6317 - accuracy: 0.7935 - val_loss: 2.6442 - val_accuracy: 0.7197\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 4s 220ms/step - loss: 0.5953 - accuracy: 0.8065 - val_loss: 2.4846 - val_accuracy: 0.7325\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.7503 - accuracy: 0.7745 - val_loss: 2.6139 - val_accuracy: 0.7134\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.6193 - accuracy: 0.7980 - val_loss: 2.6138 - val_accuracy: 0.7197\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.6432 - accuracy: 0.8026 - val_loss: 2.7307 - val_accuracy: 0.7006\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 4s 219ms/step - loss: 0.6020 - accuracy: 0.7987 - val_loss: 2.6980 - val_accuracy: 0.7134\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.6133 - accuracy: 0.7974 - val_loss: 2.6578 - val_accuracy: 0.7006\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 3s 218ms/step - loss: 0.6413 - accuracy: 0.7928 - val_loss: 2.7904 - val_accuracy: 0.7197\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 3s 215ms/step - loss: 0.6561 - accuracy: 0.7915 - val_loss: 2.5355 - val_accuracy: 0.7134\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.5883 - accuracy: 0.8039 - val_loss: 2.6626 - val_accuracy: 0.7261\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.6098 - accuracy: 0.8098 - val_loss: 2.6032 - val_accuracy: 0.7197\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 3s 217ms/step - loss: 0.5827 - accuracy: 0.8131 - val_loss: 2.5636 - val_accuracy: 0.7197\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.5572 - accuracy: 0.8150 - val_loss: 2.6611 - val_accuracy: 0.7643\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 3s 216ms/step - loss: 0.5792 - accuracy: 0.8196 - val_loss: 2.6076 - val_accuracy: 0.7643\n",
            "1530 [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Chatbot started. type /stop to stop the bot')\n",
        "def runChatbot():\n",
        "\twhile(True):\n",
        "\t\tsen=input('QUERY : ')\n",
        "\t\tif sen=='/stop':\n",
        "\t\t\tbreak\n",
        "\t\ttokens = Tokenizer.texts_to_sequences([sen])\n",
        "\t\ttokens = pad_sequences(tokens, maxlen = 64)\n",
        "\t\tprediction = model.predict(np.array(tokens))\n",
        "\t\tpred = np.argmax(prediction)\n",
        "\t\tprint('RESPONSE : ',responses[classes[pred]])\n",
        "runChatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCx80jGquore",
        "outputId": "c0ab8d3b-8f5c-4484-bc8b-4701c7f7d0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot started. type /stop to stop the bot\n",
            "QUERY : tell about isro\n",
            "RESPONSE :  ISRO is the primary agency in India to perform tasks related to space based applications, space exploration and development of related technologies\n",
            "QUERY : tell me about pslv\n",
            "RESPONSE :  Polar Satellite Launch Vehicle\n",
            "QUERY : what is gslv mark 3\n",
            "RESPONSE :   Geosynchronous Satellite Launch Vehicle Mark II GSLV Mk II is the largest launch vehicle developed by India, which is currently in operation\n",
            "QUERY : /stop\n"
          ]
        }
      ]
    }
  ]
}